{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0cca021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68610ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "B, D = 8, 16\n",
    "\n",
    "x = torch.randn((B, D), device=device)\n",
    "norm = nn.RMSNorm(normalized_shape=D, device=device)\n",
    "y_torch = norm(x)\n",
    "\n",
    "mean_square = torch.sum(x * x, axis=1) / x.shape[1]\n",
    "_rstd = torch.rsqrt(mean_square + 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911a88c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = norm.weight\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2417da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def rms_norm_fwd_kernel(\n",
    "    X_ptr,\n",
    "    X_row_stride,\n",
    "    Y_ptr,\n",
    "    Y_row_stride,\n",
    "    W_ptr,\n",
    "    RSTD_ptr,\n",
    "    RSTD_row_stride,\n",
    "    n_cols,\n",
    "    eps,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    row_id = tl.program_id(0).to(tl.int64)\n",
    "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    mask = col_offsets < n_cols\n",
    "\n",
    "    X_ptr += row_id * X_row_stride\n",
    "    Y_ptr += row_id * Y_row_stride\n",
    "    RSTD_ptr += row_id * RSTD_row_stride\n",
    "\n",
    "    x = tl.load(\n",
    "        pointer=X_ptr + col_offsets,\n",
    "        mask=mask,\n",
    "        other=0.0,\n",
    "    )\n",
    "    w = tl.load(pointer=W_ptr + col_offsets, mask=mask, other=0.0)\n",
    "\n",
    "    # cast to float32 for computation then cast back to original type\n",
    "    x_dtype = x.dtype\n",
    "    x.to(tl.float32)\n",
    "\n",
    "    mean_square = tl.sum(x * x, axis=0) / n_cols\n",
    "    rstd = tl.rsqrt(mean_square + eps)\n",
    "\n",
    "    # cache rms for backward (small compared to X and saves *, sum, /, sqrt)\n",
    "    tl.store(pointer=RSTD_ptr, value=rstd)\n",
    "\n",
    "    x = x * rstd\n",
    "    x = x.to(x_dtype)\n",
    "\n",
    "    y = x * w\n",
    "    y = y.to(x_dtype)\n",
    "\n",
    "    tl.store(\n",
    "        pointer=Y_ptr + col_offsets,\n",
    "        value=y,\n",
    "        mask=mask,\n",
    "    )\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def rmsnorm_bwd_kernel(\n",
    "    X_ptr,\n",
    "    X_row_stride,\n",
    "    X_dtype: tl.constexpr,\n",
    "    dX_ptr,\n",
    "    dX_row_stride,\n",
    "    dY_ptr,\n",
    "    dY_row_stride,\n",
    "    W_ptr,\n",
    "    dW_ptr,\n",
    "    dW_row_stride,\n",
    "    RSTD_ptr,\n",
    "    RSTD_row_stride,\n",
    "    n_rows,\n",
    "    n_cols,\n",
    "    rows_per_program: tl.constexpr,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    row_block_id = tl.program_id(0).to(tl.int64)\n",
    "    row_start = row_block_id * rows_per_program\n",
    "    row_end = min((row_block_id +1) * rows_per_program, n_rows)\n",
    "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    mask = col_offsets < n_cols\n",
    "\n",
    "    X_ptr += row_block_id * X_row_stride\n",
    "    dX_ptr += row_block_id * dX_row_stride\n",
    "    dY_ptr += row_block_id * X_row_stride\n",
    "    dW_ptr += row_block_id * dW_row_stride\n",
    "    RSTD_ptr += row_block_id\n",
    "\n",
    "    x = tl.load(pointer=X_ptr + col_offsets, mask=mask, other=0.0)\n",
    "    dy = tl.load(pointer=dY_ptr + col_offsets, mask=mask, other=0.0)\n",
    "    w = tl.load(pointer=W_ptr + col_offsets, mask=mask, other=0.0)\n",
    "\n",
    "\n",
    "def rms_norm_forward(\n",
    "    x: torch.Tensor, w: torch.Tensor, eps: float = 1e-5\n",
    ") -> torch.Tensor:\n",
    "    n_rows, n_cols = x.shape\n",
    "    y = torch.empty_like(x, dtype=x.dtype, device=x.device)\n",
    "    rstd = torch.empty(n_rows, dtype=torch.float32, device=x.device)\n",
    "\n",
    "    BLOCK_SIZE = triton.next_power_of_2(n_cols)\n",
    "    rms_norm_fwd_kernel[(n_rows,)](\n",
    "        X_ptr=x,\n",
    "        X_row_stride=x.stride(0),\n",
    "        Y_ptr=y,\n",
    "        Y_row_stride=y.stride(0),\n",
    "        W_ptr=w,\n",
    "        RSTD_ptr=rstd,\n",
    "        RSTD_row_stride=rstd.stride(0),\n",
    "        n_cols=n_cols,\n",
    "        eps=eps,\n",
    "        BLOCK_SIZE=BLOCK_SIZE,\n",
    "    )\n",
    "\n",
    "    return y, rstd\n",
    "\n",
    "\n",
    "y, rstd = rms_norm_forward(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abaadc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(y, y_torch, atol=1e-4, rtol=1e-4)\n",
    "torch.testing.assert_close(rstd, _rstd, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062fec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
