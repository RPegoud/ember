optimizer:
  lr: 5e-4
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95

trainer:
  max_epochs: 1
  precision: "bf16-mixed"
  gradient_clip_val: 1.0
  accumulate_grad_batches: 4
  log_every_n_steps: 10 

data:
  dataset: "roneneldan/TinyStories"
  split: "train"
  batch_size: 64
  num_workers: 4
  max_seq_len: 512

scheduler:
  warmup_steps: 1e3
  max_steps: 5e4
