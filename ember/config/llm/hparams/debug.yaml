env:
  accelerator: "auto" # [auto, cuda, cpu, gpu, tpu]
  n_devices: 1 # int, list[int], str, -1 = all devices
  precision: "bf16-mixed" # 32, 16, bf16 / mixed (model params remain in 32), true (params are get cast)

optimizer:
  lr: 5e-4
  weight_decay: 0.1

# sampler: # TODO: add sampler to config with target


train:
  epochs: ~
  gradient_clip_val: 1.0
  max_steps: 30 # number of optimiser steps
  val_interval: 10

callbacks:
  generate:
    max_new_tokens: 50

data:
  dataset: "roneneldan/TinyStories"
  streaming: true
  n_val_samples: 128
  batch_size: 4 # the effective batch size
  target_batch_size: 64 # the batch size to reach via gradient accumulation

scheduler:
  warmup_steps: 1e3
  max_steps: 5e4
