{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbc9cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanpegoud/Documents/Projects/ember/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from typing import Optional\n",
    "from ember import (\n",
    "    Transformer,\n",
    "    GroupedQueryAttn,\n",
    "    MultiHeadLatentAttn,\n",
    "    HFTokenizer,\n",
    "    TopKSampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14fb94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10daaf910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50f4092",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Transformer.__init__() got an unexpected keyword argument 'attn_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     13\u001b[39m tk = HFTokenizer(model = \u001b[33m\"\u001b[39m\u001b[33mopenai-community/gpt2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# model = Transformer(\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     vocab_size=len(tk.base),\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#     model_dim=D,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#     n_attn_blocks=3,\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m model = \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMultiHeadLatentAttn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmla_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_attn_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Transformer.__init__() got an unexpected keyword argument 'attn_module'"
     ]
    }
   ],
   "source": [
    "B, S, D = 8, 1024, 512\n",
    "mla_kwargs = {\n",
    "    \"latent_dim\": 256,\n",
    "    \"pos_dim\": 128,\n",
    "    \"n_heads\": 16,\n",
    "}\n",
    "gqa_kwargs = {\n",
    "    \"n_query_heads\": 8,\n",
    "    \"n_query_groups\": 4,\n",
    "}\n",
    "# \n",
    "# tk = Tokenizer()\n",
    "tk = HFTokenizer(model = \"openai-community/gpt2\")\n",
    "# model = Transformer(\n",
    "#     vocab_size=len(tk.base),\n",
    "#     model_dim=D,\n",
    "#     hidden_dim=1024,\n",
    "#     attn_module=GroupedQueryAttn,\n",
    "#     attn_kwargs=gqa_kwargs,\n",
    "#     n_attn_blocks=3,\n",
    "# )\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=tk.vocab_size,\n",
    "    model_dim=D,\n",
    "    hidden_dim=1024,\n",
    "    attn_module=MultiHeadLatentAttn,\n",
    "    attn_kwargs=mla_kwargs,\n",
    "    n_attn_blocks=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3639692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|pad|><|pad|>Hey there', 'How are you?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [\"Hey there\", \"How are you?\"]\n",
    "x = tk(txt, mode=\"inference\")\n",
    "tk.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|pad|><|pad|>Hey there BertClaim Sim moreover notor troop Tutorial worth troop Clinical———————————————— idiotegu routine PACK DOE DOE Obs marches Bott exchange Bott swirlingRush Ricanigntyigntyegu Applied rel monsters usability rel prioritiesatta Reese gasped idiotbc Assistant visionary rel wastelandgradient 113amples Bott idiottall Audiolution',\n",
       " 'How are you? remind elapsedvalue Monday Kalshake Veget tagsNap asteroids dividends problems Crown Episcopal Soci specifically66 specifically Bes mould trafficking Episcopallinedocadoocado Collabor RS RS Crown\":\"\",\"dra behavioraliris Ascension EU dividendsmatter Collabor upstream RS specificallyshake regulates ignoredYuph Credit159 Bes RS Collabor']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(\n",
    "    txt,\n",
    "    max_new_tokens=50,\n",
    "    sampler=TopKSampler(50),\n",
    "    tokenizer=tk,\n",
    ")\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
