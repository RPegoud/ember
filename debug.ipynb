{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbc9cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanpegoud/Documents/Projects/ember/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from typing import Optional\n",
    "from ember import (\n",
    "    Transformer,\n",
    "    GroupedQueryAttn,\n",
    "    MultiHeadLatentAttn,\n",
    "    HFTokenizer,\n",
    "    TopKSampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14fb94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11219b550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50f4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Transformer(\n",
      "  (embed): Embedding(50258, 512)\n",
      "  (attn_blocks): ModuleList(\n",
      "    (0-2): 3 x AttentionBlock(\n",
      "      (mlp): SwiGLU(\n",
      "        (W): Linear(in_features=512, out_features=682, bias=False)\n",
      "        (V): Linear(in_features=512, out_features=682, bias=False)\n",
      "        (W2): Linear(in_features=682, out_features=512, bias=False)\n",
      "      )\n",
      "      (norm): RMSNorm()\n",
      "      (attn): MultiHeadLatentAttn(\n",
      "        (fused_qkv_down_proj): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (q_up_proj): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (k_up_proj): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (v_up_proj): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (q_pos_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (k_pos_proj): Linear(in_features=512, out_features=8, bias=True)\n",
      "        (o_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (rope): RoPE()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      ")>\n",
      "Parameter count: 3.21e+07\n"
     ]
    }
   ],
   "source": [
    "B, S, D = 8, 1024, 512\n",
    "mla_kwargs = {\n",
    "    \"latent_dim\": 256,\n",
    "    \"pos_dim\": 128,\n",
    "    \"n_heads\": 16,\n",
    "}\n",
    "gqa_kwargs = {\n",
    "    \"n_query_heads\": 8,\n",
    "    \"n_query_groups\": 4,\n",
    "}\n",
    "# \n",
    "# tk = Tokenizer()\n",
    "tk = HFTokenizer(model = \"openai-community/gpt2\")\n",
    "# model = Transformer(\n",
    "#     vocab_size=len(tk.base),\n",
    "#     model_dim=D,\n",
    "#     hidden_dim=1024,\n",
    "#     attn_module=GroupedQueryAttn,\n",
    "#     attn_kwargs=gqa_kwargs,\n",
    "#     n_attn_blocks=3,\n",
    "# )\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=tk.vocab_size,\n",
    "    model_dim=D,\n",
    "    hidden_dim=1024,\n",
    "    attn_module=MultiHeadLatentAttn,\n",
    "    attn_kwargs=mla_kwargs,\n",
    "    n_attn_blocks=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3639692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|pad|><|pad|>Hey there', 'How are you?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [\"Hey there\", \"How are you?\"]\n",
    "x = tk(txt, mode=\"inference\")\n",
    "tk.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa68d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|pad|><|pad|>Hey there BertClaim Sim moreover notor troop Tutorial worth troop Clinical———————————————— idiotegu routine PACK DOE DOE Obs marches Bott exchange Bott swirlingRush Ricanigntyigntyegu Applied rel monsters usability rel prioritiesatta Reese gasped idiotbc Assistant visionary rel wastelandgradient 113amples Bott idiottall Audiolution',\n",
       " 'How are you? remind elapsedvalue Monday Kalshake Veget tagsNap asteroids dividends problems Crown Episcopal Soci specifically66 specifically Bes mould trafficking Episcopallinedocadoocado Collabor RS RS Crown\":\"\",\"dra behavioraliris Ascension EU dividendsmatter Collabor upstream RS specificallyshake regulates ignoredYuph Credit159 Bes RS Collabor']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(\n",
    "    txt,\n",
    "    max_new_tokens=50,\n",
    "    sampler=TopKSampler(50),\n",
    "    tokenizer=tk,\n",
    ")\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
